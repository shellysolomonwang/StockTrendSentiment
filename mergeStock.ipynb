{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Provides a merged dataset for the stock to be analyzed.\n",
    "\n",
    "Clean datasets from 4 sources filtered by the desire stock and merge them into one.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/shelly/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/shelly/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download('punkt')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "#stock = 'TSLA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Tianrui Wang\"\n",
    "__copyright__ = \"Copyright 2020, DS4A Women's Summit\"\n",
    "__email__ = \"shellysolomonwang@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVader(stock):\n",
    "    \"\"\"\n",
    "    return df with vader scores for each comment/post\n",
    "    \n",
    "    \"\"\"\n",
    "    comments_posts = pd.read_csv('./data/posts_and_comments.csv', index_col=0)\n",
    "    comments_posts.date_created = pd.to_datetime(comments_posts.date_created)\n",
    "    comments_posts['weekday'] = pd.to_datetime(comments_posts.date_created).dt.weekday\n",
    "    # 0 - Monday,4 - Friday, 5 - Sat, 6 - Sunday\n",
    "    comments_posts['datetime']= comments_posts.date_created\n",
    "    # change Satureday posts to Friday\n",
    "    comments_posts.loc[comments_posts.weekday==5,'datetime'] = comments_posts[comments_posts.weekday==5].date_created - datetime.timedelta(days=1)\n",
    "    # mark Sunday posts to Satureday\n",
    "    comments_posts.loc[comments_posts.weekday==6,'datetime'] = comments_posts[comments_posts.weekday==6].date_created - datetime.timedelta(days=2)\n",
    "    comments_posts = comments_posts[comments_posts.tickers.str.contains(stock)]\n",
    "\n",
    "    # initialize VADER \n",
    "    vad = SentimentIntensityAnalyzer()\n",
    "    # update with new words\n",
    "    new_words = {\"moon\":2, \"bear\":-2, \"printer\":2, \"bull\":2, \"drill\":2, \"put\":-2, \"call\":2, \"long\":2, \"short\":-2, \"up\":2, \"down\":-2, \"green\": 2, \"red\":-2, \"drop\":-0.5, \"rocket\":1.5}\n",
    "    vad.lexicon.update(new_words)\n",
    "    \n",
    "    # iterate through the whole dataframe and calculate compound vad score\n",
    "    vad_compound = []\n",
    "    for index, row in comments_posts.iterrows():\n",
    "        msg = row[\"body\"]\n",
    "        vad_compound.append(vad.polarity_scores(msg)[\"compound\"])\n",
    "    comments_posts[\"vader_score\"] = vad_compound\n",
    "    comments_posts.drop(columns = ['weekday'], inplace = True)\n",
    "    return comments_posts\n",
    "\n",
    "def cleanVader(stock):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    comments = getVader(stock)\n",
    "    # comments['datetime'] = pd.to_datetime(comments.timestamp).dt.date\n",
    "    vader_df = pd.DataFrame(columns = ['vader_mean','vader_std', 'comment_count','pos_count','neg_count'])\n",
    "    vader_df.vader_mean = comments.groupby('datetime').vader_score.mean()\n",
    "    vader_df.vader_std = comments.groupby('datetime').vader_score.std().fillna(0)\n",
    "    vader_df.comment_count = comments.groupby('datetime').vader_score.count()\n",
    "    vader_df.pos_count = comments.groupby('datetime')['vader_score'].apply(lambda x: (x>0).sum())\n",
    "    vader_df.neg_count = comments.groupby('datetime')['vader_score'].apply(lambda x: (x<0).sum())\n",
    "    \n",
    "    pos_mean = comments[comments.vader_score > 0].groupby('datetime').mean().rename(columns={'vader_score':'pos_mean'})\n",
    "    neg_mean = comments[comments.vader_score < 0].groupby('datetime').mean().rename(columns={'vader_score':'neg_mean'})\n",
    "    \n",
    "    pos_sum = comments[comments.vader_score > 0].groupby('datetime').sum().rename(columns={'vader_score':'pos_sum'})\n",
    "    neg_sum = comments[comments.vader_score < 0].groupby('datetime').sum().rename(columns={'vader_score':'neg_sum'})\n",
    "    \n",
    "    vader_df = vader_df.join(pos_mean, how='outer').join(neg_mean,how='outer').join(pos_sum, how='outer').join(neg_sum, how='outer').fillna(0)\n",
    "    \n",
    "    return vader_df\n",
    "\n",
    "def getCommentsVader(stock):\n",
    "    \"\"\"\n",
    "    return a comments_df with vader scores for each comment\n",
    "    \"\"\"\n",
    "    # read comments + filter for the stock\n",
    "    comments_df =pd.read_csv('./data/comment_tickers_mentioned_python_new.csv')\n",
    "    comments_df = comments_df[comments_df.tickers.str.contains(stock)]\n",
    "    \n",
    "    # initialize VADER \n",
    "    vad = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # iterate through the whole dataframe and calculate compound vad score\n",
    "    vad_compound = []\n",
    "    for index, row in comments_df.iterrows():\n",
    "        msg = row[\"body\"]\n",
    "        vad_compound.append(vad.polarity_scores(msg)[\"compound\"])\n",
    "    comments_df[\"vader_score\"] = vad_compound\n",
    "    comments_df.drop(columns = ['weekday','type'], inplace = True)\n",
    "    return comments_df\n",
    "\n",
    "def cleanCommentsVader(stock):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    comments = getCommentsVader(stock)\n",
    "    comments['datetime'] = pd.to_datetime(comments.timestamp).dt.date\n",
    "    vader_df = pd.DataFrame(columns = ['vader_mean','vader_std', 'comment_count','pos_count','neg_count'])\n",
    "    vader_df.vader_mean = comments.groupby('datetime').vader_score.mean()\n",
    "    vader_df.vader_std = comments.groupby('datetime').vader_score.std().fillna(0)\n",
    "    vader_df.comment_count = comments.groupby('datetime').vader_score.count()\n",
    "    vader_df.pos_count = comments.groupby('datetime')['vader_score'].apply(lambda x: (x>0).sum())\n",
    "    vader_df.neg_count = comments.groupby('datetime')['vader_score'].apply(lambda x: (x<0).sum())\n",
    "    \n",
    "    pos_count = comments[comments.vader_score > 0].groupby('datetime').mean().rename(columns={'vader_score':'pos_mean'})\n",
    "    neg_count = comments[comments.vader_score < 0].groupby('datetime').mean().rename(columns={'vader_score':'neg_mean'})\n",
    "    vader_df = vader_df.join(pos_count, how='outer').join(neg_count,how='outer').fillna(0)\n",
    "    return vader_df\n",
    "\n",
    "def getPrice(stock):\n",
    "    \"\"\"\n",
    "    return price_df for the stock with close & volume\n",
    "    \"\"\"\n",
    "    # read df + filter stocks\n",
    "    price_df = pd.read_csv('./data/top30_stock_price.csv', index_col=0, parse_dates=True)\n",
    "    price_df = price_df[price_df.ticker == stock]\n",
    "    return price_df\n",
    "\n",
    "def cleanPrice(stock):\n",
    "    \"\"\"\n",
    "    Note: NaN existed in result\n",
    "    1. calculate close_T-1 (previous day closing price)\n",
    "    2. calculate target variable (binary) of next day's return\n",
    "        - 1 for positive return\n",
    "        - 0 for negative return\n",
    "    3. calculate returnPrev1 (1-day log return by closing price)\n",
    "    \"\"\"\n",
    "    price_df = getPrice(stock)\n",
    "    price_df['close_T-1'] = price_df.close.shift(periods =1)\n",
    "    price_df['Y']= price_df.apply(lambda x: 1 if (x['close'] - x['close_T-1']) > 0 else 0, axis=1).shift(periods =-1)\n",
    "    # returnPrev1 = ln(close_T / close_T-1)\n",
    "    price_df['logreturnPrev1'] = np.log(price_df.close/price_df['close_T-1'])\n",
    "    price_df['returnPrev1'] = price_df.close.pct_change(periods = 1)\n",
    "    price_df['returnPrev5'] = price_df.close.pct_change(periods = 5)\n",
    "    return price_df.drop(columns = ['ticker'])\n",
    "\n",
    "def getPriceYahoo(stock):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    price_df = yf.download(stock,'2018-04-02')[['Open', 'Close', 'Volume']]\n",
    "    return price_df\n",
    "\n",
    "def cleanPriceYahoo(stock):\n",
    "    price_df = getPriceYahoo(stock)\n",
    "    price_df['close_T-1'] = price_df.Close.shift(periods =1)\n",
    "    price_df['Y']= price_df.apply(lambda x: 1 if (x['Close'] - x['close_T-1']) > 0 else 0, axis=1).shift(periods =-1)\n",
    "    price_df['logReturnClosePrev1'] = np.log(price_df.Close/price_df['close_T-1'])\n",
    "    price_df['returnClosePrev1'] = price_df.Close.pct_change(periods = 1)\n",
    "    price_df['returnClosePrev5'] = price_df.Close.pct_change(periods = 5)\n",
    "    price_df['returnOpenPrev1'] = price_df.Open.pct_change(periods = 1)\n",
    "    price_df['returnOpenPrev5'] = price_df.Open.pct_change(periods = 5)\n",
    "    return price_df\n",
    "    \n",
    "def getVIX():\n",
    "    vix_df = pd.read_csv('./data/vixcurrent.csv', skiprows=1, index_col=0)\n",
    "    vix_df.index = pd.to_datetime(vix_df.index, format = '%m/%d/%Y')\n",
    "    vix_df['VIX_Close_T-1'] = vix_df['VIX Close'].shift(periods=1)\n",
    "    vix_df['vix_returnPrev1'] = np.log(vix_df['VIX Close']/vix_df['VIX_Close_T-1'])\n",
    "    return vix_df\n",
    "\n",
    "def getPopularity(stock):\n",
    "    popularity_df = pd.read_csv('./data/popularity_cleaned.csv')\n",
    "    popularity_df = popularity_df[popularity_df.ticker ==stock]\n",
    "    return popularity_df.set_index('datetime').drop(columns = ['ticker']).add_prefix('popularity_')\n",
    "\n",
    "def merge(stock):\n",
    "    \"\"\"\n",
    "    main function\n",
    "    return cleaned df for model\n",
    "    \"\"\"\n",
    "    # get & clean comments, return vader matrix\n",
    "    vader = cleanVader(stock)\n",
    "    \n",
    "    # get & clean price\n",
    "    price = cleanPrice(stock)\n",
    "    \n",
    "    # get vix\n",
    "    vix = getVIX()\n",
    "    \n",
    "    # get popularity\n",
    "    popularity = getPopularity(stock)\n",
    "    \n",
    "    return popularity.join(price, how='inner').join(vix, how='left').join(vader, how='left').fillna(0)\n",
    "\n",
    "def mergeYahoo(stock):\n",
    "    \"\"\"\n",
    "    main function\n",
    "    return cleaned df for model\n",
    "    \"\"\"\n",
    "    # get & clean comments, return vader matrix\n",
    "    vader = cleanVader(stock)\n",
    "    \n",
    "    # get & clean price\n",
    "    price = cleanPriceYahoo(stock)\n",
    "    \n",
    "    # get vix\n",
    "    vix = getVIX()\n",
    "    \n",
    "    # get popularity\n",
    "    popularity = getPopularity(stock)\n",
    "    \n",
    "    return popularity.join(price, how='inner').join(vix, how='left').join(vader, how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = getVader('TSLA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sum = comments[comments.vader_score > 0].groupby('datetime').sum().rename(columns={'vader_score':'pos_sum'})\n",
    "neg_sum = comments[comments.vader_score < 0].groupby('datetime').sum().rename(columns={'vader_score':'neg_sum'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>1.1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-11</th>\n",
       "      <td>0.9855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-23</th>\n",
       "      <td>0.9912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-10</th>\n",
       "      <td>6.4549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-11</th>\n",
       "      <td>18.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-12</th>\n",
       "      <td>44.6814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-13</th>\n",
       "      <td>34.8090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-14</th>\n",
       "      <td>28.8833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pos_sum\n",
       "datetime           \n",
       "2018-01-03   0.2263\n",
       "2018-01-04   1.1159\n",
       "2018-01-05   0.6369\n",
       "2018-01-11   0.9855\n",
       "2018-01-23   0.9912\n",
       "...             ...\n",
       "2020-08-10   6.4549\n",
       "2020-08-11  18.6800\n",
       "2020-08-12  44.6814\n",
       "2020-08-13  34.8090\n",
       "2020-08-14  28.8833\n",
       "\n",
       "[607 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>-0.6954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-11</th>\n",
       "      <td>-0.8837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-12</th>\n",
       "      <td>-0.7674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18</th>\n",
       "      <td>-0.6553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-29</th>\n",
       "      <td>-0.8643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-10</th>\n",
       "      <td>-2.2210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-11</th>\n",
       "      <td>-6.3191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-12</th>\n",
       "      <td>-19.5969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-13</th>\n",
       "      <td>-11.5057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-14</th>\n",
       "      <td>-8.7134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>541 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            neg_sum\n",
       "datetime           \n",
       "2018-01-04  -0.6954\n",
       "2018-01-11  -0.8837\n",
       "2018-01-12  -0.7674\n",
       "2018-01-18  -0.6553\n",
       "2018-01-29  -0.8643\n",
       "...             ...\n",
       "2020-08-10  -2.2210\n",
       "2020-08-11  -6.3191\n",
       "2020-08-12 -19.5969\n",
       "2020-08-13 -11.5057\n",
       "2020-08-14  -8.7134\n",
       "\n",
       "[541 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
